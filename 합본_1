import datetime
from tracemalloc import stop
import cv2
from cv2 import VideoCapture
import threading
import os
import time
import keyboard
import numpy as np
from PIL import Image
import sys




path = 'dataset'
recognizer = cv2.face.LBPHFaceRecognizer_create()
base_path = os.path.dirname(os.path.abspath("__file__"))
base_path = base_path+"\\"+str(id)
#if not os.path.exists(base_path): #이 명령어는 해당 사용자 폴더가 없을시 폴더를 자동으로 만들어 준다
    #os.makedirs(base_path)
i = 0

recognizer = cv2.face.LBPHFaceRecognizer_create()
recognizer.read('trainer/trainer.yml')
cascadePath = "haarcascade_frontalface_default.xml"
faceCascade = cv2.CascadeClassifier(cascadePath);
font = cv2.FONT_HERSHEY_SIMPLEX
count1 = 0
count2 = 0
count3 = 0
count4 = 0
count5 = 0
count6 = 0

k = cv2.waitKey(10) & 0xff



class showcamThread(threading.Thread): #
    def __init__(self,previewName, cam_num):
        super(showcamThread, self).__init__()
        self.previewName = previewName
        self.cam_num = cam_num
        
    def run(self): #이 함수로 캠이 켜지게 된다.
        show_cam(self.previewName, self.cam_num)
        
    def stop(self):
        self.power = False
        self.quit()
        self.wait(3000)
        
class writecamThread(threading.Thread):
    def __init__(self,previewName, cam_num):
        super(writecamThread, self).__init__()
        self.previewName = previewName
        self.cam_num = cam_num
        
    def run(self): #이 함수로 캠이 켜지게 된다.
        write_cam(self.previewName, self.cam_num)
        
class Captureface(threading.Thread):
    def __init__(self):
        super(Captureface, self).__init__()
        
    def run(self):
        capture_img()
        
        
        
def show_cam(previewName, cam_num):
    global base_path
    global count1
    global id
    global k
    global count4
    


    cam = cv2.VideoCapture(cam_num)
    minW = 0.1*cam.get(3)
    minH = 0.1*cam.get(4)
    video = -1 # 객체를 담을 수 있는 변수 선언(-1로 초기화한거임.)
   

    while True:
        ret, img =cam.read()
        gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)
        
        faces = faceCascade.detectMultiScale( 
            gray,
            scaleFactor = 1.2,
            minNeighbors = 5,
            minSize = (int(minW), int(minH)),
        )
        for(x,y,w,h) in faces:
            cv2.rectangle(img, (x,y), (x+w,y+h), (0,255,0), 2)
            id, confidence = recognizer.predict(gray[y:y+h,x:x+w])
            # Check if confidence is less them 100 ==> "0" is perfect match 
            if (confidence < 80):
                id = id
                print(id)
                confidence = "  {0}%".format(round(100 - confidence))
                
                
                if (id == 1):
                    A = input("")
                    if (A == 'D'):
                        base_path = os.path.dirname(os.path.abspath("__file__"))
                        base_path = base_path+"\\"+str(id)
                        if not os.path.exists(base_path): #이 명령어는 해당 사용자 폴더가 없을시 폴더를 자동으로 만들어 준다
                            os.makedirs(base_path)
                            write_cam('inside', 1)
                            print("image save")
                    
            else:
                id = "unknown"
                confidence = "  {0}%".format(round(100 - confidence))
            
            cv2.putText(img, str(id), (x+5,y-5), font, 1, (255,255,255), 2)
            cv2.putText(img, str(confidence), (x+5,y+h-5), font, 1, (255,255,0), 1)  
        cv2.imshow('camera' ,img)
        reply = input("")
        if reply == 'T':
            # 멀티쓰레드를 종료하는 stop 메소드를 실행함
            break
        
            
            
            
        
    print("\n [INFO] Exiting Program and cleanup stuff")
    cam.release()
        
def write_cam(previewName, cam_num):
    global base_path
    global count1
    global id
    global count4
     

    count1 += 1
    cam = cv2.VideoCapture(1)
    video = -1 # 객체를 담을 수 있는 변수 선언(-1로 초기화한거임.)
    if cam.isOpened():
        rval, frame = cam.read()
        
    else:
        rval = False
        
    
    time.sleep(2)
    cv2.imwrite((str(id) + "/User" + '.' + str(id) + '.' + str(count1) + ".jpg"), frame)#사진이 저장되는 이름 
    
def capture_img():
    global count6
    global count5
    
    
    while True:
        CR = input("")
        if (CR == 'q'):
            FD = input("DO you want capture your face? :")
            if (FD == 'NO'):
                print("back to program")
            
            elif ( FD == 'Yes'):
                cam = cv2.VideoCapture(0)
                cam.set(3, 640) # set video width
                cam.set(4, 480) # set video height
                face_detector = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')
                # For each person, enter one numeric face id
                count5 = count5 + 1
                face_id = count5
                print("\n [INFO] Initializing face capture. Look the camera and wait ...")
                # Initialize individual sampling face count
                
                def getImagesAndLabels(path):
                    imagePaths = [os.path.join(path,f) for f in os.listdir(path)]     
                    faceSamples=[]
                    ids = []
                    for imagePath in imagePaths:
                        PIL_img = Image.open(imagePath).convert('L') # convert it to grayscale
                        img_numpy = np.array(PIL_img,'uint8')
                        id = int(os.path.split(imagePath)[-1].split(".")[1])
                        faces = face_detector.detectMultiScale(img_numpy)
                        for (x,y,w,h) in faces:
                            faceSamples.append(img_numpy[y:y+h,x:x+w])
                            ids.append(id)
                    return faceSamples,ids


        
        
                while(True):
                    ret, img = cam.read()
                    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
                    faces = face_detector.detectMultiScale(gray, 1.3, 5)
                    for (x,y,w,h) in faces:
                        cv2.rectangle(img, (x,y), (x+w,y+h), (255,0,0), 2)     
                        count6 += 1
                        # Save the captured image into the datasets folder
                        cv2.imwrite("dataset/User." + str(face_id) + '.' + str(count6) + ".jpg", gray[y:y+h,x:x+w])
                        #cv2.imshow('image', img)
                    k = cv2.waitKey(100) & 0xff # Press 'ESC' for exiting video
                    #if k == 27:
                        #break
                    if count6 >= 20: # Take 30 face sample and stop video
                        count6 = 0
                        break
                    
                print ("\n [INFO] Training faces. It will take a few seconds. Wait ...")
                faces,ids = getImagesAndLabels(path)
                recognizer.train(faces, np.array(ids))
                recognizer.write('trainer/trainer.yml')
                print("\n [INFO] {0} faces trained. Exiting Program".format(len(np.unique(ids))))
                reply = input("")
                if reply == 'T':
                    # 멀티쓰레드를 종료하는 stop 메소드를 실행함
                    break
                
            
    # Do a bit of cleanup
        print("\n [INFO] Exiting Program and cleanup stuff")
        
    

     
            
if __name__ == "__main__":
    thread1 = showcamThread("front", 0)
    thread2 = Captureface()
    
    OO = input("")
    if (OO == 'P'):
        thread1.start()
        
        
    elif (OO == 'I'):
        thread2.start()
    
 
